{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euc2MzxXOXKC",
        "outputId": "251b18cd-5181-49aa-e362-f489c460e6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: brasil-data in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (4.11.2)\n",
            "Requirement already satisfied: cachier<2.0.0,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (1.5.4)\n",
            "Requirement already satisfied: html5lib<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (1.1)\n",
            "Requirement already satisfied: lxml<5.0.0,>=4.6.4 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (4.9.3)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (1.5.3)\n",
            "Requirement already satisfied: random-user-agent<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (2.31.0)\n",
            "Requirement already satisfied: xlrd<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from brasil-data) (2.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.10.0->brasil-data) (2.5)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from cachier<2.0.0,>=1.5.3->brasil-data) (3.0.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from cachier<2.0.0,>=1.5.3->brasil-data) (2.8.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from cachier<2.0.0,>=1.5.3->brasil-data) (0.1.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib<2.0,>=1.1->brasil-data) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib<2.0,>=1.1->brasil-data) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.0->brasil-data) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.0->brasil-data) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.0->brasil-data) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->brasil-data) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->brasil-data) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->brasil-data) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->brasil-data) (2023.7.22)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade brasil-data\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# import python data science libs\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# imports sentiment Analyses\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# imports brazil market data\n",
        "from brdata import xpi\n",
        "from brdata import fundamentus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WwE7Mq1Ykdc"
      },
      "source": [
        "# Análise de sentimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8xKUg5IYECb"
      },
      "outputs": [],
      "source": [
        "class Platform:\n",
        "  def __init__(self, url, tag, name):\n",
        "    self.url = url\n",
        "    self.tag = tag\n",
        "    self.name = name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# faz fetch das noticias e cria headlines\n",
        "def fetch_headlines(platform: Platform, paper, console=False):\n",
        "  response = requests.get(platform.url)\n",
        "  soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  headlines = soup.find_all(platform.tag, string=re.compile(paper, flags=re.IGNORECASE), limit=20)\n",
        "  if console: print(f\"Noticias lidas de {platform.name}: {len(headlines)}\")\n",
        "\n",
        "  return headlines"
      ],
      "metadata": {
        "id": "on11MauP4W56"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# traduz texto para inglês e melhora qualidade da análise do vader sentiment\n",
        "def translate_text(text, target_language='en'):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(text, dest=target_language)\n",
        "    return translation.text"
      ],
      "metadata": {
        "id": "tMeIcOTC4Zix"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockSentiment:\n",
        "  def __init__(self, paper, console=False, text=False):\n",
        "    self._paper = paper\n",
        "    self._console = console\n",
        "    self._text = text\n",
        "    self._sentiment_score = 0\n",
        "    self._total_score = 0\n",
        "    self._action = \"NEUTRO\"\n",
        "\n",
        "    self._platforms = [\n",
        "        Platform(f\"https://news.google.com/search?q={paper}\",\n",
        "                tag=\"a\", name=\"Google News\"),\n",
        "        Platform(f\"https://br.investing.com/search/?q={paper}&tab=news\",\n",
        "                tag=\"a\", name=\"Investing.com\"),\n",
        "        Platform(f\"https://einvestidor.estadao.com.br/?s={paper}\",\n",
        "                tag=\"h2\", name=\"e-investidor\"),\n",
        "        Platform(f\"https://exame.com/busca/{paper}/\", tag=\"a\", name=\"Exame\"),\n",
        "        Platform(f\"https://www.seudinheiro.com/?s={paper}\", tag=\"a\", name=\"Seu Dinheiro\"),\n",
        "                ]\n",
        "\n",
        "  def _calculate_sentiment(self, headlines):\n",
        "    for headline in headlines:\n",
        "      text = translate_text(headline.text)\n",
        "      if self._text: print(text)\n",
        "      analyzer = SentimentIntensityAnalyzer()\n",
        "      sentiment = analyzer.polarity_scores(text)\n",
        "      self._sentiment_score = self._sentiment_score + sentiment['compound']\n",
        "\n",
        "    return self._sentiment_score\n",
        "\n",
        "  def _analyse_platforms(self):\n",
        "    for platform in self._platforms:\n",
        "      headlines = fetch_headlines(platform, self._paper, self._console)\n",
        "      self._sentiment_score = self._calculate_sentiment(headlines)\n",
        "      self._total_score = self._total_score + self._sentiment_score\n",
        "      if self._console: print(f\"Sentimento {platform.name}: {self._sentiment_score} \\n\")\n",
        "\n",
        "\n",
        "  def stock_analysis(self):\n",
        "    self._analyse_platforms()\n",
        "    media = self._total_score / len(self._platforms)\n",
        "\n",
        "    if self._console:\n",
        "      print(f\"Total: {round(self._total_score, 2)}\")\n",
        "      print(f\"Média Sobre Total: {round(media, 2)}\\n\")\n",
        "\n",
        "    analyse = xpi.analise(self._paper)\n",
        "    if media > 0.8: self._action = \"COMPRA\"\n",
        "    elif media < -0.8: self._action = \"VENDA\"\n",
        "\n",
        "    return {\n",
        "        \"action\":\n",
        "            self._action,\n",
        "        \"xpi_analise\":\n",
        "            analyse,\n",
        "        \"fundamentus\":\n",
        "            fundamentus.detalhes(self._paper.upper())\n",
        "        }"
      ],
      "metadata": {
        "id": "fRb73D_kpWcT"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgsEtNueRYbp",
        "outputId": "7112fc7e-e50c-45ea-843e-e3523ca26e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business: BANCO BRADESCO S.A. PN N1\n",
            "Setor: Intermediários Financeiros\n",
            "Action: NEUTRO\n",
            "Action XPI: neutro\n"
          ]
        }
      ],
      "source": [
        "stock = StockSentiment(\"bbdc4\").stock_analysis()\n",
        "print(f\"Business: { stock['fundamentus']['Empresa'] }\")\n",
        "print(f\"Setor: { stock['fundamentus']['Setor'] }\")\n",
        "print(f\"Action: { stock['action'] }\")\n",
        "print(f\"Action XPI: { stock['xpi_analise']['Recomendação'] }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGhto8kyYeKG"
      },
      "source": [
        "# Análise de tendência\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SCgDuZlpgv1S"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importe os dados da ação\n",
        "# dados = pd.read_csv(\"dados_acao.csv\")\n",
        "\n",
        "# # Calcule a média móvel de 50 períodos\n",
        "# media_movel_50 = dados[\"preco\"].rolling(50).mean()\n",
        "\n",
        "# # Calcule a média móvel de 200 períodos\n",
        "# media_movel_200 = dados[\"preco\"].rolling(200).mean()\n",
        "\n",
        "# # Plote os dados\n",
        "# plt.plot(dados[\"data\"], dados[\"preco\"], label=\"Preço\")\n",
        "# plt.plot(dados[\"data\"], media_movel_50, label=\"Média móvel de 50 períodos\")\n",
        "# plt.plot(dados[\"data\"], media_movel_200, label=\"Média móvel de 200 períodos\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # Analise a tendência\n",
        "# if media_movel_50 > media_movel_200:\n",
        "#   print(\"A tendência é de alta.\")\n",
        "# elif media_movel_50 < media_movel_200:\n",
        "#   print(\"A tendência é de baixa.\")\n",
        "# else:\n",
        "#   print(\"A tendência é lateral.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j90asFSvDga3"
      },
      "source": [
        "# Calculo de risco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n-Sts5S3DjWa"
      },
      "outputs": [],
      "source": [
        "# def calcula_risco(dados):\n",
        "#   \"\"\"\n",
        "#   Calcula o risco de uma ação usando o desvio padrão.\n",
        "\n",
        "#   Args:\n",
        "#     dados: Uma série de dados com os retornos da ação.\n",
        "\n",
        "#   Returns:\n",
        "#     O desvio padrão dos retornos da ação.\n",
        "#   \"\"\"\n",
        "\n",
        "#   retornos = dados[\"Retorno\"]\n",
        "#   desvio_padrao = retornos.std()\n",
        "#   return desvio_padrao\n",
        "\n",
        "# # Exemplo de uso\n",
        "\n",
        "# dados = pd.read_csv(\"dados.csv\")\n",
        "# risco = calcula_risco(dados)\n",
        "# print(risco)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyKKKzzq1lerLJcW10GtgJ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}